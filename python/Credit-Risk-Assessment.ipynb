{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Assessment\n",
    "\n",
    "A credit risk is the risk of default on a debt that may arise from a borrower failing to make required payments. Someone who defaults on their loans can mean a lot of money lost for a financial institution and at the same time, false negatives (i.e. declining a loan when they are capable of repaying the money) can mean money lost from interest. The following is a method for predicting credit risk of a customer. We use the German Credit Data stored in the UCI Machine Learning Repository [here](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Munging\n",
    "\n",
    "The first step is to transform the raw data into another format that is appropriate for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Remove font warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the text file that contains the German Credit Data.\n",
    "credit_risk_df = pd.read_csv('data/german.data', delimiter=' ', \n",
    "                            names = [\"checkingAccount\",\n",
    "                                     \"duration\",\n",
    "                                     \"creditHistory\",\n",
    "                                     \"purpose\",\n",
    "                                     \"amount\",\n",
    "                                     \"savingsAccount\",\n",
    "                                     \"employed\",\n",
    "                                     \"installmentRate\",\n",
    "                                     \"gender\",\n",
    "                                     \"otherDebtors\",\n",
    "                                     \"residentYears\",\n",
    "                                     \"property\",\n",
    "                                     \"age\",\n",
    "                                     \"installmentPlans\",\n",
    "                                     \"housing\",\n",
    "                                     \"existingCredits\",\n",
    "                                     \"job\",\n",
    "                                     \"dependents\",\n",
    "                                     \"telephone\",\n",
    "                                     \"foreign\",\n",
    "                                     \"risk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the German credit dataset is quite unreadable. We will need to map each feature value to its corresponding value that is human readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ordinal Values have a clear ordering of the variables.\n",
    "original_ordinal_vals = {\"checkingAccount\": {\"A11\": \"low\", \"A12\": \"medium\", \"A13\": \"high\", \"A14\": \"none\"},\n",
    "                 \"creditHistory\": {\"A30\": \"excellent\", \"A31\" : \"good\", \"A32\": \"okay\", \"A33\": 'bad', \"A34\": \"very bad\"},\n",
    "                 \"savingsAccount\": {\"A61\": \"low\", \"A62\": \"medium\", \"A63\": \"high\", \"A64\": \"very high\", \"A65\": \"none\"},\n",
    "                 \"employed\": {\"A71\": \"0\", \"A72\": \"< 1\", \"A73\": \"1-4\", \"A74\": \"4-7\", \"A75\": \">= 7\"},\n",
    "                 \"job\": {\"A171\": \"unemployed/unskilled/non-resident\", \"A172\": \"unskilled/resident\", \"A173\": \"employed/skilled\", \"A174\": \"employed/highly-skilled\"}\n",
    "                }\n",
    "\n",
    "#Categorical Values do not have an ordering.\n",
    "original_categorical_vals = {\"purpose\": {\"A40\":\"car\", \"A41\": \"car\", \"A42\":\"furniture\", \"A43\": \"television\", \n",
    "                                         \"A44\": \"domestic appliances\", \"A45\": \"repairs\", \"A46\": \"education/business\",\n",
    "                                         \"A48\": \"education/business\", \"A49\": \"education/business\", \"A410\": \"other\"},\n",
    "                             \"gender\": {\"A91\": \"male\", \"A92\": \"female\", \"A93\": \"male\", \"A94\": \"male\", \"A95\": \"female\"},\n",
    "                             \"otherDebtors\": {\"A101\": \"none\", \"A102\": \"co-applicant\", \"A103\": \"guarantor\"},\n",
    "                             \"installmentPlans\": {\"A141\": \"yes\", \"A142\": \"yes\", \"A143\": \"no\"},\n",
    "                             \"housing\": {\"A151\": \"rent\", \"A152\": \"own\", \"A153\": \"free\"}\n",
    "                }\n",
    "\n",
    "credit_risk_df['risk'] = credit_risk_df['risk'].map({1:0,2:1})\n",
    "\n",
    "#Delete features that will not make a difference to predicting credit risk.\n",
    "del credit_risk_df['property']\n",
    "del credit_risk_df['telephone']\n",
    "del credit_risk_df['foreign']\n",
    "\n",
    "credit_risk_df.replace(original_ordinal_vals, inplace=True)\n",
    "credit_risk_df.replace(original_categorical_vals, inplace=True)\n",
    "\n",
    "#Convert from DM to USD.\n",
    "credit_risk_df['amount'] = credit_risk_df['amount'].map(lambda x : ((x * 58)/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a copy of the original dataframe before encoding columns.\n",
    "credit_risk_orig_df = credit_risk_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform label encoding on ordinal values. Label encoding will still\n",
    "#capture the ordering of the data.\n",
    "def handle_ordinal_values(attribute, categories, df):\n",
    "    cat_str = attribute + 'Cat'\n",
    "    df[attribute] = pd.Categorical(df[attribute], categories)\n",
    "    df[cat_str] = df[attribute].cat.codes\n",
    "\n",
    "ordinal_mapping = {'checkingAccount':[\"none\",\"low\", \"medium\", \"high\"], \n",
    "                   'creditHistory': [\"very bad\", \"bad\", \"okay\", \"good\", \"excellent\"],\n",
    "                   'savingsAccount': [\"none\", \"low\", \"medium\", \"high\", \"very high\"],\n",
    "                   'employed': [\"0\", \"< 1\", \"1-4\", \"4-7\", \">= 7\"],\n",
    "                   'job': [\"unemployed/unskilled/non-resident\",\"unskilled/resident\",\"employed/skilled\",\"employed/highly-skilled\"]}\n",
    "\n",
    "for feature, feature_vals in ordinal_mapping.items():\n",
    "    handle_ordinal_values(feature, feature_vals, credit_risk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform one-hot encoding for categorical columns.\n",
    "credit_risk_df = pd.get_dummies(credit_risk_df, columns=[\"purpose\", \"gender\", \"otherDebtors\", \"installmentPlans\", \"housing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The different datatypes within the original dataframe.\n",
    "credit_risk_orig_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the averages of the different features and group by risk where \n",
    "#0 is good risk and 1 is bad risk.\n",
    "credit_risk_orig_df.groupby('risk').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by risk and aggregate the top value count for each feature.\n",
    "credit_risk_orig_df.groupby('risk').agg(lambda x: x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the averages for each risk group, we notice that people who request for less money and are older are lower risk than those who are \n",
    "requesting for more money and are younger in age. So lets use seaborn to plot the data and fit a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "age_vs_amount_plots = sns.lmplot(x='age', y='amount', data=credit_risk_df, hue='risk', col='risk', size=8, aspect=.6)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "age_vs_amount_plots.fig.suptitle(\"Comparing Age to Credit Amount Requested\")\n",
    "age_vs_amount_plots.set_axis_labels(\"Age\", \"Amount in Dollars Requested\")\n",
    "titles=['Good Credit Risk', 'Bad Credit Risk']\n",
    "for ax, title in zip(age_vs_amount_plots.axes.flat, titles):\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compare the credit risks of people against the amount they have in savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_risks = credit_risk_df.groupby(['savingsAccount', 'risk']).size()\n",
    "num_risks_unstacked = num_risks.unstack()\n",
    "num_risks_unstacked.plot(kind='bar', figsize=(10,5), fontsize=15)\n",
    "plt.legend(['Good Credit Risk', 'Bad Credit Risk'], fontsize=15)\n",
    "plt.title(\"Credit Risks of People Per Amount in Savings Account\", fontsize=15)\n",
    "plt.ylabel(\"# of People\", fontsize=15)\n",
    "plt.xlabel(\"Amount in Savings Account\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows that most people have little in their savings account and more people are good credit risk than bad. However, a different way of looking at this information is to compare the the ratios or percentages of bad vs good credit risk per amount in savings account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "risks_percentages = num_risks.groupby(level=0).apply(lambda x : x / x.sum() * 100).unstack()\n",
    "risks_percentages[1].plot(kind='line', figsize=(10,5),fontsize=15)\n",
    "plt.title(\"% of People Who Are Classified as Bad Credit Risk Compared Against Amount in Savings\", fontsize=15)\n",
    "plt.ylabel(\"% of Bad Credit Risks\", fontsize=15)\n",
    "plt.xlabel(\"Amount in Savings Account\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the percentage of people with bad credit risk vs those with good credit risk is lower when they have more money in their savings account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the number of dependent and group by good vs bad credit risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dependents = credit_risk_df.groupby(['dependents','risk']).size().unstack()\n",
    "num_dependents.columns = ['Good Credit Risk', 'Bad Credit Risk']\n",
    "num_dependents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular dataset, there is only 1 or 2 dependents and we don't see much of a correlation here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another visual that might be helpful is seeing what each gender is requesting money for. In this particular dataset, the different requests or purposes include buying a car, furniture, television, repairs, domestic appliances, education/business related incentive, and \"other\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_vs_purpose = credit_risk_orig_df.groupby(['purpose', 'gender']).size().unstack()\n",
    "gender_vs_purpose.plot(kind='line', marker='o', figsize=(17,10))\n",
    "plt.title(\"What are people borrowing for?\")\n",
    "plt.ylabel(\"# of People\")\n",
    "plt.xlabel(\"Purpose for borrowing credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, for both males and females, the #1 reason for borrowing is to buy a car. And it seems in all cases besides for domestic appliances, more men are requesting for a loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These different visuals help to understand our data better. It is hard to pick out with the human eye all these correlations. Pandas, matplotlib, and seaborn make it incredibly easy to find these underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will do some predictive analysis on classifying potential customers as bad or good credit risk. First, we will need to create a model to perform the prediction. For classification models, some classic machine learning algorithms people use are logistic regression and random forest. Here, we will try out both and pick the model that performs better on a new dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a good first choice because it is fast, highly scalable, doesn't require much tuning and is easy to regularize. Also, the model outputs a set of probabilities which can be more useful than class labels. Here, we will use scikit-learn to create our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train and test dataframes. First we are going to drop the \n",
    "# categorical variables and only keep the one-hot encoded versions of them.\n",
    "credit_risk_df = credit_risk_df.drop(['checkingAccount', 'creditHistory', 'savingsAccount', 'employed', 'job'], axis=1)\n",
    "\n",
    "X = credit_risk_df.drop('risk', axis=1)\n",
    "y = credit_risk_df['risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model.\n",
    "model = LogisticRegression()\n",
    "#Use cross validation to prevent overfitting. Here we pick 10 fold cross\n",
    "#validation. i.e. we take out a set of the data to use for test and \n",
    "#leave in the rest for training.\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to regularize our logistic regression to see if we can increase our accuracy. Here, we try using grid search to perform an exhaustive search over the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'penalty': ['l1','l2']}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=10, scoring='neg_log_loss')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what grid search found as the best C and penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these values in our logistic regression and see if it improves the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = clf.best_params_['C']\n",
    "penalty = clf.best_params_['penalty']\n",
    "model = LogisticRegression(C=C, penalty=penalty)\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try Random Forest and see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is another popular algorithm for both classification and regression. It requires very little tuning and is less prone to overfitting. Random forest is an aggregation of decision tress where each tree classifies an observation in a dataset. Since random forest aggregates many classifiers, it is considered an emsemble method. Using scikit learn again, we will create our random forest for classification and take a look at its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = RFC(n_estimators = 200)\n",
    "scores = cross_val_score(model, X,y, cv=10, scoring='accuracy' )\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sticking with our random forest model, we are now going to fit the model on our training set and then see how well the random forest performs on our test set. The results are shown in the cross-tabulation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(credit_risk_df, test_size = 0.3)\n",
    "model.fit(train.loc[:, train.columns != 'risk'], train['risk'])\n",
    "preds = model.predict(test.loc[:,train.columns !='risk'])\n",
    "pd.crosstab(index=test['risk'], columns=preds, rownames=['Actual Value'], colnames=['Predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of random forest is seeing which features work best for our model. Here we rank the importance of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in train.columns if col not in ['risk']]\n",
    "importances = pd.DataFrame({'features':cols,'importance_value':model.feature_importances_})\n",
    "importances = importances.sort_values('importance_value',ascending=False).set_index('features')\n",
    "importances.plot(figsize=(15,10), kind=\"barh\", legend=False, title=\"Ranking Order of Importance of Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, amount of money requested, age and the amount of money in their checkings account are the most important features for classifying a new test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Borrower Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's imagine we have a new potential borrower and they are requesting to borrow $15k. We will use our model to see if we would rate this customer as good or bad credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for cleaning the data to be consumed by our random forest model.\n",
    "def clean_data(customer):\n",
    "    for feature, feature_vals in ordinal_mapping.items():\n",
    "        handle_ordinal_values(feature, feature_vals, customer)\n",
    "    customer = pd.get_dummies(customer, columns=[\"purpose\", \"gender\", \"otherDebtors\", \"installmentPlans\", \"housing\"])\n",
    "    customer = customer.reindex(columns = X.columns, fill_value=0)\n",
    "    return customer\n",
    "\n",
    "#Borrower's information\n",
    "customer_info = {'checkingAccount': 'medium', \n",
    "                 'duration': 6, \n",
    "                 'creditHistory': 'okay', \n",
    "                 'purpose': 'television', \n",
    "                 'amount': 15000,\n",
    "                 'savingsAccount': 'low', \n",
    "                 'employed': '>= 7', \n",
    "                 'installmentRate': 2, \n",
    "                 'gender': 'female', \n",
    "                 'otherDebtors': 'none', \n",
    "                 'residentYears': 4, 'age': 25, \n",
    "                 'installmentPlans': 'no', \n",
    "                 'housing': 'rent', \n",
    "                 'existingCredits': 1, \n",
    "                 'job': 'employed/skilled', \n",
    "                 'dependents': '1'}\n",
    "\n",
    "perspective_borrower = pd.DataFrame(customer_info, index=[0])\n",
    "perspective_borrower_clean = clean_data(perspective_borrower)\n",
    "prediction = model.predict(perspective_borrower_clean)\n",
    "print(\"Bad Credit Risk\" if prediction[0] else \"Good Credit Risk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Features\n",
    "\n",
    "These are some additional features we'd like to incorporate into this demo for the future:\n",
    "\n",
    "* Add Dask to speed up computation.\n",
    "* Add benchmarks to measure performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
