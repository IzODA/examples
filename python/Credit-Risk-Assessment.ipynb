{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Assessment\n",
    "\n",
    "A credit risk is the risk of default on a debt that may arise from a borrower failing to make required payments. Someone who defaults on their loans can mean a lot of money lost for a financial institute and at the same time, false negatives (i.e. declining a loan when they are capable of repaying the money) can mean money lost from interest. The following is a method for predicting credit risk of a customer. We use German Credit Data stored in the UCI Machine Learning Repository [here](https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Munging\n",
    "\n",
    "We need to transform the raw data into another format that is appropriate for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the csv file that contains the German Credit Data.\n",
    "credit_risk_df = pd.read_csv('data/german.data', delimiter=' ', \n",
    "                            names = [\"checkingAccount\",\n",
    "                                     \"duration\",\n",
    "                                     \"creditHistory\",\n",
    "                                     \"purpose\",\n",
    "                                     \"amount\",\n",
    "                                     \"savingsAccount\",\n",
    "                                     \"employed\",\n",
    "                                     \"installmentRate\",\n",
    "                                     \"gender\",\n",
    "                                     \"otherDebtors\",\n",
    "                                     \"residentYears\",\n",
    "                                     \"property\",\n",
    "                                     \"age\",\n",
    "                                     \"installmentPlans\",\n",
    "                                     \"housing\",\n",
    "                                     \"existingCredits\",\n",
    "                                     \"job\",\n",
    "                                     \"dependents\",\n",
    "                                     \"telephone\",\n",
    "                                     \"foreign\",\n",
    "                                     \"risk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the German credit dataset is quite unreadable. We will need to map each feature value to its coresponding description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ordinal Values have a clear ordering of the variables.\n",
    "original_ordinal_vals = {\"checkingAccount\": {\"A11\": \"low\", \"A12\": \"medium\", \"A13\": \"high\", \"A14\": \"none\"},\n",
    "                 \"creditHistory\": {\"A30\": \"excellent\", \"A31\" : \"good\", \"A32\": \"okay\", \"A33\": 'bad', \"A34\": \"very bad\"},\n",
    "                 \"savingsAccount\": {\"A61\": \"low\", \"A62\": \"medium\", \"A63\": \"high\", \"A64\": \"very high\", \"A65\": \"none\"},\n",
    "                 \"employed\": {\"A71\": \"0\", \"A72\": \"< 1\", \"A73\": \"1-4\", \"A74\": \"4-7\", \"A75\": \">= 7\"},\n",
    "                 \"job\": {\"A171\": \"unemployed/unskilled/non-resident\", \"A172\": \"unskilled/resident\", \"A173\": \"employed/skilled\", \"A174\": \"employed/highly-skilled\"}\n",
    "                }\n",
    "\n",
    "#Categorical Values do not have an ordering.\n",
    "original_categorical_vals = {\"purpose\": {\"A40\":\"car\", \"A41\": \"car\", \"A42\":\"furniture\", \"A43\": \"television\", \n",
    "                                         \"A44\": \"domestic appliances\", \"A45\": \"repairs\", \"A46\": \"education/business\",\n",
    "                                         \"A48\": \"education/business\", \"A49\": \"education/business\", \"A410\": \"other\"},\n",
    "                             \"gender\": {\"A91\": \"male\", \"A92\": \"female\", \"A93\": \"male\", \"A94\": \"male\", \"A95\": \"female\"},\n",
    "                             \"otherDebtors\": {\"A101\": \"none\", \"A102\": \"co-applicant\", \"A103\": \"guarantor\"},\n",
    "                             \"installmentPlans\": {\"A141\": \"yes\", \"A142\": \"yes\", \"A143\": \"no\"},\n",
    "                             \"housing\": {\"A151\": \"rent\", \"A152\": \"own\", \"A153\": \"free\"}\n",
    "                }\n",
    "\n",
    "credit_risk_df['risk'] = credit_risk_df['risk'].map({1:0,2:1})\n",
    "\n",
    "#Delete features that will not make a difference to predicting credit risk.\n",
    "del credit_risk_df['property']\n",
    "del credit_risk_df['telephone']\n",
    "del credit_risk_df['foreign']\n",
    "\n",
    "credit_risk_df.replace(original_ordinal_vals, inplace=True)\n",
    "credit_risk_df.replace(original_categorical_vals, inplace=True)\n",
    "\n",
    "#Convert from DM to USD.\n",
    "credit_risk_df['amount'] = credit_risk_df['amount'].map(lambda x : ((x * 58)/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credit_risk_orig_df = credit_risk_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform label encoding.\n",
    "def handle_ordinal_values(attribute, categories, df):\n",
    "    cat_str = attribute + 'Cat'\n",
    "    df[attribute] = pd.Categorical(df[attribute], categories)\n",
    "    df[cat_str] = df[attribute].cat.codes\n",
    "\n",
    "ordinal_mapping = {'checkingAccount':[\"none\",\"low\", \"medium\", \"high\"], \n",
    "                   'creditHistory': [\"very bad\", \"bad\", \"okay\", \"good\", \"excellent\"],\n",
    "                   'savingsAccount': [\"none\", \"low\", \"medium\", \"high\", \"very high\"],\n",
    "                   'employed': [\"0\", \"< 1\", \"1-4\", \"4-7\", \">= 7\"],\n",
    "                   'job': [\"unemployed/unskilled/non-resident\",\"unskilled/resident\",\"employed/skilled\",\"employed/highly-skilled\"]}\n",
    "\n",
    "for feature, feature_vals in ordinal_mapping.items():\n",
    "    handle_ordinal_values(feature, feature_vals, credit_risk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform one-hot encoding\n",
    "credit_risk_df = pd.get_dummies(credit_risk_df, columns=[\"purpose\", \"gender\", \"otherDebtors\", \"installmentPlans\", \"housing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_orig_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the averages of the different features and group by risk where \n",
    "#0 is good risk and 1 is bad risk. \n",
    "credit_risk_orig_df.groupby('risk').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by risk and aggregate the top value count for each feature.\n",
    "credit_risk_orig_df.groupby('risk').agg(lambda x: x.value_counts().index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the averages for each risk group, we notice that people who request for less money and are older are lower risk than those who are \n",
    "requesting for more money and are younger in age. So lets use seaborn to plot the data and fit a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "age_vs_amount_plots = sns.lmplot(x='age', y='amount', data=credit_risk_df, hue='risk', col='risk', size=8, aspect=.6)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "age_vs_amount_plots.fig.suptitle(\"Comparing Age to Credit Amount Requested\")\n",
    "age_vs_amount_plots.set_axis_labels(\"Age\", \"Amount in Dollars Requested\")\n",
    "titles=['Good Credit Risk', 'Bad Credit Risk']\n",
    "for ax, title in zip(age_vs_amount_plots.axes.flat, titles):\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_risks = credit_risk_df.groupby(['savingsAccount', 'risk']).size()\n",
    "num_risks_unstacked = num_risks.unstack()\n",
    "num_risks_unstacked.plot(kind='bar', figsize=(10,5), fontsize=15)\n",
    "plt.legend(['Good Credit Risk', 'Bad Credit Risk'], fontsize=15)\n",
    "plt.title(\"Credit Risks of People Per Savings Account Amount\", fontsize=15)\n",
    "plt.ylabel(\"# of People\", fontsize=15)\n",
    "plt.xlabel(\"Savings Account Amount\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph that might be more helpful to understand credit risks of people based on savings account would be showing the different percentages per savings account amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks_percentages = num_risks.groupby(level=0).apply(lambda x : x / x.sum() * 100).unstack()\n",
    "risks_percentages[1].plot(kind='line', figsize=(10,5),fontsize=15)\n",
    "plt.title(\"Percentage of People with Bad Credit compared with Savings Account Amount\", fontsize=15)\n",
    "plt.ylabel(\"% of People with Bad Credit\", fontsize=15)\n",
    "plt.xlabel(\"Savings Account Amount\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are less people with bad credit who have more money in their savings account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dependents = credit_risk_df.groupby(['dependents','risk']).size().unstack()\n",
    "num_dependents.columns = ['Good Credit Risk', 'Bad Credit Risk']\n",
    "num_dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_vs_purpose = credit_risk_orig_df.groupby(['purpose', 'gender']).size().unstack()\n",
    "gender_vs_purpose.plot(kind='line', marker='o', figsize=(15,10))\n",
    "plt.title(\"What are people borrowing for?\")\n",
    "plt.ylabel(\"# of People\")\n",
    "plt.xlabel(\"Purpose for borrowing credit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These different visuals help to understand our data better. It is hard to pick out with the human eye all these correlations. Pandas, matplotlib, and seaborn make it incredibly easy to find these underlying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification models some classic machine learning algorithms that people use are logistic regression and Random Forest. Here we will try out both and pick the model that performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is nice because it is fast, highly scalable, doesn't require tuning and is easy to regularize. Also, the output of logistic regression is a set of probabilities. It is useful to have probabilities as opposed to the actual class label because we can easily adjust the threshold to label datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_risk_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create train and test dataframes. First we are going to drop the \n",
    "# categorical variables.\n",
    "credit_risk_df = credit_risk_df.drop(['checkingAccount', 'creditHistory', 'savingsAccount', 'employed', 'job'], axis=1)\n",
    "\n",
    "X = credit_risk_df.drop('risk', axis=1)\n",
    "y = credit_risk_df['risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model.\n",
    "model = LogisticRegression()\n",
    "#Use cross validation to prevent overfitting. Here we pick 10 fold cross\n",
    "#validation. i.e. we take out a set of the data to use for test and \n",
    "#leave in the rest for training.\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to regularize our logistic regression to make it more generalized. Here, we try using grid search to perform an exhaustive search over the parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'penalty': ['l1','l2']}\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv=10, scoring='neg_log_loss')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=.01, penalty='l2')\n",
    "scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is another popular algorithm for both classification and regression. It requires very little tuning and less prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular classification algorithm. It is an aggregation of decision trees where each tree is composed of a series of decisions to classify an observation in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = RFC(n_estimators = 200)\n",
    "scores = cross_val_score(model, X,y, cv=10, scoring='accuracy' )\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to fit the model on our training set and then see how well the random forest performs on our test set. The results are show in the cross-tabulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(credit_risk_df, test_size = 0.3)\n",
    "model.fit(train.loc[:, train.columns != 'risk'], train['risk'])\n",
    "preds = model.predict(test.loc[:,train.columns !='risk'])\n",
    "pd.crosstab(index=test['risk'], columns=preds, rownames=['Actual Value'], colnames=['Predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the strongest points of random forest is seeing which features work best for each tree. Here we rank the importance of the features in our random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in train.columns if col not in ['risk']]\n",
    "importances = pd.DataFrame({'features':cols,'importance_value':model.feature_importances_})\n",
    "importances = importances.sort_values('importance_value',ascending=False).set_index('features')\n",
    "importances.plot(figsize=(15,10), kind=\"barh\", legend=False, title=\"Ranking Order of Importance of Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Customer Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(customer):\n",
    "    for feature, feature_vals in ordinal_mapping.items():\n",
    "        handle_ordinal_values(feature, feature_vals, customer)\n",
    "    customer = pd.get_dummies(customer, columns=[\"purpose\", \"gender\", \"otherDebtors\", \"installmentPlans\", \"housing\"])\n",
    "    customer = customer.reindex(columns = X.columns, fill_value=0)\n",
    "    return customer\n",
    "\n",
    "#New customer info\n",
    "customer_info = {'checkingAccount': 'medium', \n",
    "                 'duration': 6, \n",
    "                 'creditHistory': 'okay', \n",
    "                 'purpose': 'television', \n",
    "                 'amount': 15000,\n",
    "                 'savingsAccount': 'low', \n",
    "                 'employed': '>= 7', \n",
    "                 'installmentRate': 2, \n",
    "                 'gender': 'female', \n",
    "                 'otherDebtors': 'none', \n",
    "                 'residentYears': 4, 'age': 25, \n",
    "                 'installmentPlans': 'no', \n",
    "                 'housing': 'rent', \n",
    "                 'existingCredits': 1, \n",
    "                 'job': 'employed/skilled', \n",
    "                 'dependents': '1'}\n",
    "\n",
    "perspective_customer = pd.DataFrame(customer_info, index=[0])\n",
    "perspective_customer_clean = clean_data(perspective_customer)\n",
    "model.predict(perspective_customer_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Features\n",
    "\n",
    "* Add Dask\n",
    "* Add some benchmarks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
