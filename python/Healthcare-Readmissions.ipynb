{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Healthcare Readmissions Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Preventing hospital readmissions is one of the best ways to reduce healthcare costs quickly and improve patient care in the process. This notebook demonstrates a method to predict whether a patient will be readmitted to a hospital within the 30 days after getting discharged. We use the data from 130 US hospitals for years 1999-2008 which is stored in the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This first section is to transform and prepare the raw data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "readmissions_df = pd.read_csv('data/healthcare_data.csv')\n",
    "readmissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We map the different ids in the data above to human readable values and remove all the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#There are 50 features, out of which many are unnecessary for our purpose.\n",
    "#Delete features that either have large number of missing/unknown values or will not make a difference to predicting credit risk.\n",
    "readmissions_df.drop(readmissions_df.columns[[0,1,2,5,10,11,15,16,17,18,19,20,22,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,42,43,44,45,46]], axis=1,inplace= True)\n",
    "\n",
    "replacing_values = {\"admission_type_id\": {1:\"Emergency\", 2:\"Urgent\",3:\"Elective\",4: \"Newborn\", 5: np.NaN, 6: np.NaN, 7:\"Trauma Center\", 8:np.NaN },\n",
    "                   \"discharge_disposition_id\": {1:\"Discharged to Home\",2:\"Transferred to another hospital\", 3:\"Transferred to SNF\",\n",
    "                                                4:\"Transferred to ICF\", 5:\"Transferred to another hospital\", 6:\"Discharged to home with home health service\",\n",
    "                                                7:\"Discharged against Medical advice\", 8:\"Discharged to home with home health service\",9:\"Discharged to Home\",\n",
    "                                                10:\"Transferred to another hospital\", 11:\"Expired\", 12:\"Discharged to Home\", 13:\"Hospice\",14:\"Hospice\",15:\"Transferred within this institution\",\n",
    "                                                16:\"Transferred to another hospital\", 17:\"Transferred to another hospital\", 18:np.NaN, 19:\"Hospice\", 20:\"Hospice\",21:\"Hospice\",\n",
    "                                                22:\"Transferred to another hospital\", 23:\"Transferred to another hospital\", 24:\"Transferred to SNF\",25:\"Transferred to another hospital\",\n",
    "                                                26:\"Transferred to another hospital\", 27:\"Transferred to a federal health care facility\", 28:\"Transferred to another hospital\", 29:\"Transferred to another hospital\"},\n",
    "                   \"admission_source_id\": {1:\"Physician Referral\", 2:\"Clinic Referral\", 3:\"HMO Referral\", 4:\"Transfer from a hospital\", 5: \"Transfer from a SNF\", 6:\"Transfer from another health care facility\",\n",
    "                                           7:\"Emergency Room\",8:\"Law Enforcement\", 9:np.NaN, 10:\"Transfer from a hospital\", 11:\"Normal Delivery\", 12:\"Premature Delivery\", 13:\"Sick Baby\",\n",
    "                                           14:\"Extramural Birth\", 15:np.NaN, 17:np.NaN, 18:\"Transfer from Home Health Agency\", 19:\"Transfer from Home Health Agency\", 20: np.NaN, 21:np.NaN,\n",
    "                                           22:\"Transfer from a hospital\",23:\"Normal Delivery\", 24:\"Sick Baby\", 25:\"Transfer from Ambulatory Surgery Center\", 26:\"Transfer from Hospice\"},\n",
    "                   \"age\":{\"[0-10)\":5,\"[10-20)\":15,\"[20-30)\":25,\"[30-40)\":35,\"[40-50)\":45,\"[50-60)\":55,\"[60-70)\":65,\"[70-80)\":75,\"[80-90)\":85,\"[90-100)\":95},\n",
    "                    \"A1Cresult\":{\"Norm\":\"Normal\", \">8\":\">7\"}\n",
    "                   }\n",
    "readmissions_df.replace(replacing_values,inplace = True)\n",
    "readmissions_df['readmitted'] = readmissions_df['readmitted'].map({\"NO\":0,\">30\":0,\"<30\":1})\n",
    "readmissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we take a look at the number of rows with missing values and eliminate those rows from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(readmissions_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(readmissions_df.shape)\n",
    "readmissions_df.dropna(inplace=True)\n",
    "print(readmissions_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We make a copy of the dataframe for exploratory analysis before encoding\n",
    "readmissions_orig_df = readmissions_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#One-hot encoding on all the categorical values\n",
    "readmissions_df = pd.get_dummies(readmissions_df, columns=[\"admission_type_id\",\"discharge_disposition_id\",\"admission_source_id\",\"gender\", \"insulin\", \"change\",\"diabetesMed\",\"A1Cresult\"])\n",
    "readmissions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this section, we analyze the main characteristics of the data set and explore different factors that may affect the readmission of a patient. This will help us learn more about the data before we begin predictive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "readmissions_orig_df.groupby('readmitted').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see, this data set is quite imbalanced as almost 90% of the patients in this data set have not been readmitted within 30 days. This is helpful information to know before we measure the performace of our machine learning algorithms later on. \n",
    "Now, let us see some of the most common feature values for a patient who is readmitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Mean feateres of a readmitted Patient\n",
    "mean = readmissions_orig_df.groupby('readmitted').mean()\n",
    "mean.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Mode features of a readmitted Patient\n",
    "modeValue = readmissions_orig_df.groupby('readmitted').agg(lambda x: x.value_counts().index[0])\n",
    "modeValue.ix[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see from the above results, most of the readmitted patients are over 65 years old who were admitted as an Emergency and went through a large number of lab procedures and medications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes = readmissions_orig_df.groupby(['diabetesMed','readmitted']).size().unstack()\n",
    "diabetes[1].plot(kind='bar', figsize=(8,4), fontsize=15)\n",
    "plt.title(\"Relation between Readmitted patients and Diabetes\", fontsize=15)\n",
    "plt.ylabel(\"Number of Readmitted Patients\", fontsize=15)\n",
    "plt.xlabel(\"Diabetic Patients\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From the above graph, we can see that majority of the patients who were readmitted were also diabetic. Now let's see how the types of admission and discharge can affect a patient's readmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "readmitted = readmissions_orig_df.groupby(['admission_source_id', 'readmitted']).size()\n",
    "admission_type = readmitted.groupby(level=0).apply(lambda x : x / x.sum() * 100).unstack()\n",
    "admission_type[1].dropna(inplace = True)\n",
    "admission_type[1].drop_duplicates().plot(kind='barh', figsize=(10,5), fontsize=15)\n",
    "plt.title(\"Admission types of patients readmitted\", fontsize=15)\n",
    "plt.ylabel(\"Type of admission\", fontsize=15)\n",
    "plt.xlabel(\"% of People Readmitted\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "readmitted = readmissions_orig_df.groupby(['discharge_disposition_id', 'readmitted']).size()\n",
    "readmitted_percentages = readmitted.groupby(level=0).apply(lambda x : x / x.sum() * 100).unstack()\n",
    "readmitted_percentages[1].plot(kind='pie', figsize=(10,5), fontsize=15)\n",
    "plt.xlabel(\"% of People Readmitted\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, we classify the patients as readmitted within 30 days or not. We perform this task using various machine learning algorithms and also get a better understanding of important features that help us predict the readmission of a patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "readmissions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create train and test dataframes.\n",
    "X = readmissions_df.drop('readmitted', axis=1)\n",
    "y = readmissions_df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#This method is to create n_samples of weights to handle the unbalanced data set.\n",
    "def getSampleWeights(y,weight1,weight2):\n",
    "    for n,i in enumerate(y):\n",
    "        if i==0:\n",
    "            y[n]=weight1\n",
    "        if i==1:\n",
    "            y[n]=weight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Random Forest Classifier', RFC(n_estimators=200)))\n",
    "models.append(('Extra Trees Classifier', ExtraTreesClassifier(n_estimators=200, max_depth=None,min_samples_split=2, random_state=0)))\n",
    "X = readmissions_df.drop('readmitted', axis=1)\n",
    "y = readmissions_df['readmitted']\n",
    "newY = list(y.values.flatten())\n",
    "getSampleWeights(newY,1,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "These last few steps take a while to compute due to the large size of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y, cv=kfold, scoring='accuracy', fit_params={'sample_weight':newY})\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %0.2f (%0.2f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we see from the above results, Random Forest Classifier yields the most accuracy. Now, choosing this model, we can select only the top few features and see how it affects our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Perform Feature Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "skb = SelectKBest(k=20)\n",
    "skb.fit(X,y)\n",
    "print(X.shape)\n",
    "newX = skb.transform(X)\n",
    "print(newX.shape)\n",
    "model = RFC(n_estimators=200)\n",
    "scores = cross_val_score(model, newX,y, cv=10, scoring='accuracy',fit_params={'sample_weight':newY})\n",
    "print(\"Accuracy: %0.2f \" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The above result shows us that inspite of removing more than half of the features from our data set, we still get decent accuracy and also speeds up computations.Now, using our Random Forest model, we rank the different features based on their importance in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(readmissions_df, test_size = 0.3)\n",
    "model.fit(train.loc[:, train.columns != 'readmitted'], train['readmitted'])\n",
    "cols = [col for col in train.columns if col not in ['readmitted']]\n",
    "importances = pd.DataFrame({'features':cols,'importance_value':model.feature_importances_})\n",
    "importances = importances.sort_values('importance_value',ascending=False).set_index('features')\n",
    "importances = importances[(importances.importance_value > 0.007)]\n",
    "importances.dropna().plot(figsize=(10,8), kind=\"barh\", legend=False, title=\"Ranking Order of Importance of Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we see from the above results, The number of lab procedures, medications and the time spent in the hospital by a patient are key features in determining whether he/she would be readmitted within 30 days."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
