{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing SMF 110 Monitoring Data\n",
    "\n",
    "The following demo analyzes one day's worth of SMF 110 records. SMF Records are split into three main sections. SMF Header, SMF Product Section, and the Dictionary Data Section.  There are three fields that we are interested in: **USRCPUT**, **SMFMNRST**, and **SMFMNSPN**. \n",
    "\n",
    "* **USRCPUT** gives us the total CPU time for a user task and is contained within the Dictionary Data Section. Mainframe Data Studio (MDS), divides USRCPUT into individual components: USRCPUT_TIMER, USRCPUT_FLAG, and USRCPUT_COUNT. USRCPUT_TIMER is the component we care about because it captures the CPU time. MDS also converts this value from STCK format to decimal seconds.\n",
    "* **SMFMNRST** and SMFMNRSD gives the job date and timestamp and are both found in the SMF Product Section. MDS converts the time field, SMFMNRST to a DB2 timestamp and thus, this field is sufficient enough to show both the date and time.\n",
    "* **SMF_SID** The system identifier or the z/OS LPAR.\n",
    "* **DB2REQCT** The total number of DB2® EXEC SQL and Instrumentation Facility Interface (IFI) requests issued by the user task.\n",
    "* **WMQREQCT** The total number of WebSphere® MQ requests issued by the user task.\n",
    "* **SMFMNSPN** identifies the CICS Region and is within the product section.\n",
    "\n",
    "Using Spark and Python data analysis tools, we can capture insightful information on CPU consumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#Remove font warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\", category=PendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "**Please Read** For extracting SMF110 data you have two options:\n",
    "\n",
    "**1.** Via MDS. You can use SMF110 datasets on your z/os system. If doing it this way, please run the code cells underneath \"SMF Data Extraction using Apache Spark and MDS.\"\n",
    "\n",
    "\n",
    "**2.** Via JSON. You can use our sample SMF 110 data in our github titled \"smf110.json\" and run the cell blocks under \"SMF Data Extraction using Pandas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SMF Data Extraction using Apache Spark and MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entry-point to Spark.\n",
    "spark = SparkSession.builder.appName(\"SMF110-Demo\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieving credentials to access SMF data\n",
    "\n",
    "#Create a file with the password (first line of the file) needed to access the system where\n",
    "#MDS is. Provide the absolute path in the field below.\n",
    "\n",
    "CREDENTIALS_PATH = \"\"\n",
    "def get_credentials():\n",
    "    with open(CREDENTIALS_PATH) as f:\n",
    "        password = f.readline()\n",
    "    return password\n",
    "\n",
    "password = get_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use jdbc and DvDriver for accessing the DB2 database and retrieving the SMF data.\n",
    "\n",
    "#The FQDN or IP address of the server where the database is for accessing SMF data.\n",
    "ZOS_SYSTEM = \"\"\n",
    "\n",
    "#Please provide the username in the \"url\" option value field \n",
    "#where it says \"PROVIDE-USERNAME-HERE\".\n",
    "def get_smf_data(dbtable):\n",
    "    DFReader = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"driver\", \"com.rs.jdbc.dv.DvDriver\") \\\n",
    "        .option(\"url\", \"jdbc:rs:dv://\" + ZOS_SYSTEM + \";DBTY=DVS;user=PROVIDE-USERNAME-HERE;password=\" + password) \\\n",
    "        .option(\"dbtable\", dbtable)\n",
    "    smfData = DFReader.load()\n",
    "    return smfData\n",
    "\n",
    "#The database table names defined here are the virtual mappings we created for the datasets. \n",
    "#Notice that we need to grab fields from both the CICS dictionary and product section.\n",
    "\n",
    "#The SMF110 dataset name. Please make sure to replace . with _ within the name.\n",
    "DATASET_NAME = \"\"\n",
    "cics_section = get_smf_data(\"SMF_1100P_PERFORMANCE__\" + DATASET_NAME)\n",
    "product_section = get_smf_data(\"SMF_1100P__\" + DATASET_NAME)\n",
    "cics_alias = cics_section.alias(\"cics_alias\")\n",
    "product_alias = product_section.alias(\"product_alias\")\n",
    "joined_df = cics_alias.join( \\\n",
    "    product_alias, col(\"cics_alias.PARENT_KEY\") == col(\"product_alias.CHILD_KEY\"), \"inner\")\n",
    "\n",
    "#Tran and Trannum here are the Transaction Identification and \n",
    "#the Transaction Identification Number\n",
    "filtered_df = joined_df.select( \\\n",
    "                 \"SMFMNSPN\", \"TRAN\", \"TRANNUM\", \"SMF_SID\",\"USRCPUT_TIMER\", \"USRCPUT_FLAG\",\\\n",
    "                               \"USRCPUT_COUNT\",\"SMFMNRSD\", \"SMFMNRST\",\"DB2REQCT\", \"WMQREQCT\")\n",
    "\n",
    "#Transform Spark dataframe to Pandas dataframe.\n",
    "smf110_df = filtered_df.limit(80000).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) SMF Data Extraction using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the path of the smf110.json location.\n",
    "SMF110_PATH = \"\"\n",
    "smf110_df = pd.read_json(SMF110_PATH)\n",
    "smf110_df['SMFMNRST'] = pd.to_datetime(smf110_df['SMFMNRST'],unit='ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert datatypes.\n",
    "smf110_df['TRANNUM'] = smf110_df['TRANNUM'].astype(int)\n",
    "smf110_df['USRCPUT_TIMER'] = smf110_df['USRCPUT_TIMER'].astype(float)\n",
    "smf110_df['USRCPUT_COUNT'] = smf110_df['USRCPUT_COUNT'].astype(int)\n",
    "\n",
    "orig_smf110_df = smf110_df.copy(deep=True)\n",
    "\n",
    "#only keep the CICS regions i.e. SMFMNSPN starting with \"CICS\".\n",
    "smf110_df = smf110_df[smf110_df.SMFMNSPN.str.contains(\"CICS\") == True]\n",
    "\n",
    "smf110_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The CICS Regions within dataset: \")\n",
    "orig_smf110_df.SMFMNSPN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of user tasks in this dataset: \" + str(len(smf110_df)))\n",
    "print('Total CPU Time in Seconds: {:2f}'.format(smf110_df['USRCPUT_TIMER'].sum()))\n",
    "print('Total CPU Time in Hours: {:2f}'.format(smf110_df['USRCPUT_TIMER'].sum() / 3600))\n",
    "print('Total DB2 Requests: {}'.format(smf110_df['DB2REQCT'].sum()))\n",
    "print('Total WMQ Requests: {}'.format(smf110_df['WMQREQCT'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate descriptive analysis for columns with float64 datatype. In our case, USRCPUT_TIMER.\n",
    "smf110_df.describe(include=[np.float64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Average Length of User Tasks' CPU Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.ylabel(\"Number of User Tasks\", fontsize=15)\n",
    "plt.xlabel(\"CPU Time in Seconds\", fontsize=15)\n",
    "plt.title(\"Determining Average Length of User Tasks' CPU Times\", fontsize=15)\n",
    "plt.hist(smf110_df['USRCPUT_TIMER'], bins=50, range=[0,.0001])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Number of User Tasks Per CICS Region and System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cics_run_per_region = smf110_df['SMFMNSPN'].value_counts()\n",
    "plt.figure(figsize=(16,8))\n",
    "cics_run_per_region.plot.barh(colormap='Paired')\n",
    "plt.legend(smf110_df['SMF_SID'])\n",
    "plt.xlabel(\"Number of User Tasks\", fontsize=15)\n",
    "plt.ylabel(\"CICS Region\", fontsize=15)\n",
    "plt.title(\"Total Number of User Tasks Per CICS Region, Per System\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total CPU Time (s) Accumulated Per CICS Region and System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_time_per_region = smf110_df.groupby(['SMFMNSPN'])['USRCPUT_TIMER'].sum()\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "cpu_time_per_region.plot.barh(colormap='Paired')\n",
    "plt.legend(smf110_df['SMF_SID'])\n",
    "plt.xlabel(\"Total CPU time in Seconds\", fontsize=15)\n",
    "plt.ylabel(\"CICS Region\", fontsize=15)\n",
    "plt.title(\"Total CPU Time (s) Accumulated Per CICS Region, Per System\", fontsize=15)\n",
    "cpu_time_per_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case\n",
    "\n",
    "Lets zoom in on the 2 CICS Regions that accumulate the most CPU Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf110_df[smf110_df['SMFMNSPN'] == 'CICS3AAB']['TRAN'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf110_df[smf110_df['SMFMNSPN'] == 'CICS6AAA']['TRAN'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We take a few of the transaction identifiers within the two CICS Regions of interest.\n",
    "smf110_filtered_tran_df = smf110_df[smf110_df['TRAN'].str.contains('^Y[1-5]95$|MAP')]\n",
    "smf110_filtered_tran_df = smf110_filtered_tran_df [smf110_df['SMFMNSPN'].str.contains('CICS3AAB|CICS6AAA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Transactions of interest.\n",
    "smf110_filtered_tran_df.TRAN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The CICS Regions of interest.\n",
    "smf110_filtered_tran_df.SMFMNSPN.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total CPU Time (s) Accumulated Per Transaction, Per System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_time_per_trans = smf110_filtered_tran_df.groupby(['TRAN', 'SMF_SID'])['USRCPUT_TIMER'].sum().unstack()\n",
    "cpu_time_per_trans.plot.barh(figsize=(16,8),colormap='Paired')\n",
    "plt.xlabel(\"Total CPU time in Seconds\", fontsize=15)\n",
    "plt.ylabel(\"Transaction Type\", fontsize=15)\n",
    "plt.title(\"Total CPU Time (s) Accumulated Per Transaction, Per LPAR\", fontsize=15)\n",
    "cpu_time_per_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CICS Transaction Rate Per CICS Region and LPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf110_filtered_tran_df['DATETIME_SECOND'] = smf110_filtered_tran_df['SMFMNRST'].apply(lambda x: x.second)\n",
    "trans_rate_per_region = smf110_filtered_tran_df[['SMF_SID','SMFMNSPN','DATETIME_SECOND', 'TRAN']].pivot_table(index=['SMF_SID','SMFMNSPN','DATETIME_SECOND'], columns=['TRAN'], aggfunc=len)\n",
    "trans_rate_per_region = trans_rate_per_region.fillna(0)\n",
    "sys_id = trans_rate_per_region.index.levels[0]\n",
    "cics_regions = trans_rate_per_region.index.get_level_values(1)\n",
    "num_days_cics_regions = dict()\n",
    "for j in range(len(sys_id)):\n",
    "    for i in range(len(cics_regions)):\n",
    "        num_days_cics_regions[(sys_id[j],cics_regions[i])] = num_days_cics_regions.get((sys_id[j],cics_regions[i]), 0) + 1\n",
    "start_ind = 0\n",
    "cics_trans_df = pd.DataFrame(index= list(trans_rate_per_region.columns), columns=list(num_days_cics_regions.keys()))\n",
    "for cics_region_per_sys in num_days_cics_regions:\n",
    "    end_ind = start_ind + num_days_cics_regions[cics_region_per_sys]\n",
    "    cics_rate = trans_rate_per_region.iloc[start_ind:end_ind,:].apply(lambda x : np.mean(x))\n",
    "    cics_trans_df[cics_region_per_sys] = cics_rate\n",
    "    start_ind = end_ind\n",
    "cics_trans_df.plot(kind='bar', figsize=(18,8), colormap='Paired')\n",
    "plt.xlabel(\"Transactions\", fontsize=15)\n",
    "plt.ylabel(\"CICS Transaction Rate (# of Transactions Per Second)\", fontsize=15)\n",
    "plt.title(\"CICS Transaction Rate Per CICS Region and System\", fontsize=15)\n",
    "cics_trans_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Percentage per CICS Region and LPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_percentage_per_region = smf110_filtered_tran_df[['SMF_SID','SMFMNSPN', 'USRCPUT_TIMER']].pivot_table(index=['SMF_SID','SMFMNSPN'], values=['USRCPUT_TIMER'], aggfunc=np.sum)\n",
    "#Percentage is against all the other CICS Regions in this dataset.\n",
    "cpu_percentage_per_region = cpu_percentage_per_region.apply(lambda x : x / float(orig_smf110_df['USRCPUT_TIMER'].sum()))\n",
    "cpu_percentage_per_region.plot(kind='bar', figsize=(15,8), legend=False, colormap='Paired')\n",
    "plt.xlabel(\"(LPAR, CICS Region)\", fontsize=15)\n",
    "plt.ylabel(\"Total CPU Percentage (Decimal)\", fontsize=15)\n",
    "plt.title(\"Total CPU Percentage Per CICS Region and System\", fontsize=15)\n",
    "cpu_percentage_per_region"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
